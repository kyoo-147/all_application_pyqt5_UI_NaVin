{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z022k9_Xuch6"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import cv2\n",
        "from scipy.spatial import distance\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "from keras import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kipr/opencv.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UF3juvfuqRP",
        "outputId": "e57d1458-c213-4071-fe70-b6be283e3615"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'opencv'...\n",
            "remote: Enumerating objects: 77194, done.\u001b[K\n",
            "remote: Total 77194 (delta 0), reused 0 (delta 0), pack-reused 77194\u001b[K\n",
            "Receiving objects: 100% (77194/77194), 283.58 MiB | 28.29 MiB/s, done.\n",
            "Resolving deltas: 100% (53878/53878), done.\n",
            "Updating files: 100% (3811/3811), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load train and test set\n",
        "train_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Train'\n",
        "test_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Test'\n",
        "val_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Validation'\n",
        "face_model = cv2.CascadeClassifier('/content/opencv/data/haarcascades/haarcascade_frontalface_default.xml')"
      ],
      "metadata": {
        "id": "chU2fNqiugOt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_DISTANCE = 130"
      ],
      "metadata": {
        "id": "35n4aKpIugLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(faces)>=2:\n",
        "    label = [0 for i in range(len(faces))]\n",
        "    for i in range(len(faces)-1):\n",
        "        for j in range(i+1, len(faces)):\n",
        "            dist = distance.euclidean(faces[i][:2],faces[j][:2])\n",
        "            if dist<MIN_DISTANCE:\n",
        "                label[i] = 1\n",
        "                label[j] = 1\n",
        "    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n",
        "    for i in range(len(faces)):\n",
        "        (x,y,w,h) = faces[i]\n",
        "        if label[i]==1:\n",
        "            cv2.rectangle(new_img,(x,y),(x+w,y+h),(255,0,0),1)\n",
        "        else:\n",
        "            cv2.rectangle(new_img,(x,y),(x+w,y+h),(0,255,0),1)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(new_img)\n",
        "            \n",
        "else:\n",
        "    print(\"No. of faces detected is less than 2\")"
      ],
      "metadata": {
        "id": "h6hWvM1YugI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255, horizontal_flip=True, zoom_range=0.2,shear_range=0.2)\n",
        "train_generator = train_datagen.flow_from_directory(directory=train_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "val_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "test_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode='categorical',batch_size=32)"
      ],
      "metadata": {
        "id": "gWSeMRl9ugGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg19 = VGG19(weights='imagenet',include_top=False,input_shape=(128,128,3))\n",
        "\n",
        "for layer in vgg19.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "model = Sequential()\n",
        "model.add(vgg19)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2,activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "pWdgcjoYugDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics =\"accuracy\")"
      ],
      "metadata": {
        "id": "LodCDI2RugAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(generator=train_generator,\n",
        "                              steps_per_epoch=len(train_generator)//32,\n",
        "                              epochs=20,validation_data=val_generator,\n",
        "                              validation_steps=len(val_generator)//32)"
      ],
      "metadata": {
        "id": "Rfbac7mquf-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate_generator(test_generator)"
      ],
      "metadata": {
        "id": "VSHOX19qufQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_mask_img = cv2.imread('../input/face-mask-12k-images-dataset/Face Mask Dataset/Test/WithMask/1404.png')\n",
        "sample_mask_img = cv2.resize(sample_mask_img,(128,128))\n",
        "plt.imshow(sample_mask_img)\n",
        "sample_mask_img = np.reshape(sample_mask_img,[1,128,128,3])\n",
        "sample_mask_img = sample_mask_img/255.0"
      ],
      "metadata": {
        "id": "u_WRr1eUufMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(sample_mask_img)"
      ],
      "metadata": {
        "id": "rVfg8F2HyTaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('masknet.h5')"
      ],
      "metadata": {
        "id": "EyAfoDZ4yUrr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}